Ok this is an ios app where i need an additional feature where the user will upload the Credit card statements pdf,the app will scan and ocr the transaction details --send it to an AI (Google Gemini)and create a neat category of expenses with the help of AI.

Below is a tried-and-tested recipe I use in production when I need an LLM to turn raw OCR text from any Indian credit-card statement into clean, predictable JSON that my code can validate with Pydantic.

⸻

1 ️⃣ Design the target JSON first

Keep it minimal, but leave room for future needs (currency conversion, merchant analytics, etc.).

{
  "card": {                     // optional – helps you reconcile multi-card uploads
    "issuer": "HDFC",           // SBI | HDFC | AMEX | ICICI … (free-text)
    "product": "Swiggy Card",   // free-text
    "last4": "3190",            // if visible
    "statement_period": {
      "from": "2025-04-03",
      "to":   "2025-05-02"
    }
  },
  "transactions": [
    {
      "date":        "2025-04-27",      // ISO-8601
      "description": "SWIGGY INSTA MART  BENGALORE",
      "amount":      183.00,            // always positive
      "currency":    "INR",             // 3-letter ISO
      "type":        "debit",           // debit | credit
      "derived": {                      // ***everything below is OPTIONAL***
        "category":  "Groceries",       // see enum below
        "merchant":  "Swiggy Instamart",
        "fx": {
          "original_amount": 23.60,
          "original_currency": "USD"
        }
      }
    }
  ],
  "summary": {                          // optional; handy for reconciliation
    "total_debits": 77794.69,
    "total_credits": 10953.13,
    "currency": "INR"
  }
}

Pydantic models

from decimal import Decimal
from typing import List, Optional, Literal
from datetime import date
from pydantic import BaseModel, constr


class FX(BaseModel):
    original_amount: Decimal
    original_currency: constr(regex=r"^[A-Z]{3}$")


class Derived(BaseModel):
    category: Optional[str] = None      # see enum a few lines below
    merchant: Optional[str] = None
    fx: Optional[FX] = None


class Transaction(BaseModel):
    date: date
    description: str
    amount: Decimal                        # always positive
    currency: constr(regex=r"^[A-Z]{3}$")  # default = "INR"
    type: Literal["debit", "credit"]
    derived: Optional[Derived] = None


class StatementPeriod(BaseModel):
    from_: date = Field(..., alias="from")
    to: date


class CardInfo(BaseModel):
    issuer: Optional[str] = None
    product: Optional[str] = None
    last4: Optional[constr(regex=r"^\d{4}$")] = None
    statement_period: Optional[StatementPeriod] = None


class Summary(BaseModel):
    total_debits: Decimal
    total_credits: Decimal
    currency: constr(regex=r"^[A-Z]{3}$")


class Statement(BaseModel):
    card: Optional[CardInfo] = None
    transactions: List[Transaction]
    summary: Optional[Summary] = None

Suggested category enum: ["Groceries","Dining","Fuel","Health","Bills","Shopping","Entertainment","Travel","Transfer","Cashback","Fees","Other"]

⸻

2 ️⃣ Craft a single, idempotent prompt for Gemini (or any LLM)

System:
You are a financial data extraction engine. Output ONLY valid JSON that conforms exactly to this schema:
〈〈insert the JSON schema or a URL to it〉〉
Any value not present in the input MUST be omitted (do not output null).
Amounts are numeric and always positive; use "type": "credit" or "debit" to indicate direction.
Currency is "INR" unless the line clearly shows a different ISO-code or a foreign amount in brackets.
If you’re unsure of a value, omit the key.

User:
The following is raw OCR text from a credit-card statement covering one billing period.
Your job is to extract only the transaction rows (ignore summaries, points, ads, footnotes).
Each row generally contains:
– A date (dd/mm/yyyy OR dd Mon yy etc.)
– A free-text description
– An amount followed by D/Dr/Debit or C/Cr/Credit (or a sign)
Examples of credits: “PAYMENT RECEIVED”, “REFUND”, “CREDIT”, negative amounts.

〈〈paste OCR here〉〉  



Why it works
	•	Schema-first: Gemini must conform or fail JSON validation → you can retry with higher temperature or fallback rules.
	•	Positive amounts + explicit type avoids - signs that often disappear in OCR.
	•	“Omit when unsure” prevents hallucinated fields.

⸻

3 ️⃣ Processing pipeline (first-principles view)

Step	Component	Key decisions
1	PDF → Images	Use CGPDFDocument + CGContext (iOS) or PDFKit to raster pages at ≥300 dpi.
2	OCR	Apple Vision or Tesseract. Use accuracy mode; keep bounding boxes if you later want table heuristics.
3	Pre-clean	• Drop empty lines• Collapse multiple spaces• Merge hyphenated line breaks
4	LLM prompt	The prompt above. Send at most ~4 k tokens; chunk pages if needed.
5	Pydantic validate	Statement.parse_raw(llm_output)Retry or alert if it fails.
6	Enrich categories	Optional post-processing with a tiny local model or rules if you want to save tokens.

Tip: Keep a small, regex-based fallback extractor for critical fields (date, amount) so you can flag “high-confidence” vs “needs review”.

⸻

4 ️⃣ Edge-cases & mitigation

Issue	Mitigation
Split rows across lines (long description wraps)	Instruct Gemini to join consecutive lines when the second line has no date/amount.
Multiple currencies in one row	Ask Gemini to add derived.fx only when both amount & ISO code present.
Negative-amount credits without “Cr” marker	Rule: “If amount enclosed in parentheses → credit”. Include that in the prompt if your OCR shows it.
Watermarks / ads	Vision’s “low‐confidence” flag or simple heuristics: drop lines with no digits.


⸻

Ready-to-ship usage example

payload = {
    "system": SYSTEM_PROMPT,
    "messages": [{"role":"user", "content": ocr_text}],
    "json_schema": STATEMENT_SCHEMA   # if your LLM supports function calls / JSON mode
}
resp = gemini.chat(**payload)
statement = Statement.parse_raw(resp)

........


 there can be multiple pages of transaction. Also some transaction could be credit(Cr) like in HDFC or AMEX OR ICICI meaning either i got the cashback or i had paid my credit card bills or some amount was refunded.For SBI i see it is C for Credit and D for debit.We can also extract Statement period which could be helpful.And i think All UPI transactions should fall under UPI category(because it generally mentions the merchant name so its hard to categorize them as you can see in SBI card details).
Also can you very explicitly mention that step i have to do in my ios app to implement this functionality that i can feed to my AI agent and it code exactly based on very detailed instruction for this part of the functionality.


---------

Below is a drop-in specification you can hand to an AI pair-programmer (or follow yourself) to implement multi-page statement parsing, credit/debit handling, statement-period capture, and a hard-wired “UPI” category inside your iOS app.

⸻

1️⃣  Updated JSON contract (Pydantic-ready)

{
  "card": {
    "issuer": "HDFC",
    "product": "Swiggy Card",
    "last4": "3190",
    "statement_period": {           // <— NEW (mandatory when found)
      "from": "2025-04-03",
      "to":   "2025-05-02"
    }
  },
  "transactions": [
    {
      "date":        "2025-04-27",
      "description": "UPI-NEERAJ KUMAR YADAV",
      "amount":      183.00,
      "currency":    "INR",
      "type":        "debit",        // debit | credit
      "derived": {
        "category":  "UPI",          // Enforced rule below
        "merchant":  "Neeraj Kumar Yadav"
      }
    }
  ],
  "summary": {
    "total_debits": 77794.69,
    "total_credits": 10953.13,
    "currency": "INR"
  }
}

Hard rules for the LLM
• Amounts always positive – direction is in "type"
• Recognise credit markers: CR | Cr | Credit | C or parentheses or minus sign.
• If description contains the token "UPI" → "category":"UPI" (override everything else).
• Omit any key you cannot infer with ≥ 90 % confidence (no nulls).

⸻

2️⃣  Canonical LLM prompt (multi-page safe)

SYSTEM
You are a financial data extractor. OUTPUT ONLY valid JSON matching the schema below. 
Include transactions from *all* pages. Follow the “Hard rules” section to decide debit vs credit, UPI category, and statement_period.

〈〈schema pasted here〉〉
〈〈Hard rules pasted here〉〉

USER
Here is raw OCR from a credit-card statement (all pages, page-breaks marked "===PAGE===").
Extract ONLY transaction rows + statement period.


⸻

3️⃣  iOS implementation plan — step by step, in code-order

Copy-paste each numbered block into your AI agent; every block is self-contained and deterministic.

3.1  Document intake

// 1. Let users pick/share a PDF
struct DocumentPicker: UIViewControllerRepresentable {
    func makeUIViewController(context: Context) -> UIDocumentPickerViewController {
        let picker = UIDocumentPickerViewController(forOpeningContentTypes: [.pdf])
        picker.allowsMultipleSelection = false
        return picker
    }
    func updateUIViewController(_ uiViewController: UIDocumentPickerViewController,
                                context: Context) {}
}

3.2  Render every page to images (300 dpi)

import PDFKit

func rasterPages(url: URL) throws -> [CGImage] {
    guard let doc = CGPDFDocument(url as CFURL) else { throw MyError.badPDF }
    var images: [CGImage] = []
    for pageNumber in 1...doc.numberOfPages {
        guard let page = doc.page(at: pageNumber) else { continue }
        let pageRect = page.getBoxRect(.mediaBox)
        let scale: CGFloat = 300.0 / 72.0         // 72 dpi → 300 dpi
        let width  = Int(pageRect.width  * scale)
        let height = Int(pageRect.height * scale)

        let ctx = CGContext(data: nil, width: width, height: height,
                            bitsPerComponent: 8, bytesPerRow: 0,
                            space: CGColorSpaceCreateDeviceRGB(),
                            bitmapInfo: CGImageAlphaInfo.noneSkipLast.rawValue)!
        ctx.interpolationQuality = .high
        ctx.scaleBy(x: scale, y: scale)
        ctx.drawPDFPage(page)
        if let img = ctx.makeImage() { images.append(img) }
    }
    return images
}

3.3  OCR every page with Vision

import Vision                                  // iOS 15+
                                                    // VNRecognizeTextRequest doc:  [oai_citation:0‡Apple Developer](https://developer.apple.com/documentation/vision/vnrecognizetextrequest?utm_source=chatgpt.com)
func ocr(image: CGImage) async throws -> [String] {
    let request = VNRecognizeTextRequest()
    request.recognitionLevel = .accurate
    request.usesLanguageCorrection = true
    request.recognitionLanguages = ["en-IN", "en"]  // tweak as needed
    let handler = VNImageRequestHandler(cgImage: image, options: [:])
    try handler.perform([request])
    return request.results?
        .compactMap { $0.topCandidates(1).first?.string } ?? []
}

3.4  Combine pages & pre-clean

let pageTexts = try await withThrowingTaskGroup(of: [String].self) { group -> [String] in
    for img in images { group.addTask { try await ocr(image: img) } }
    return try await group.reduce([],+)
}
let rawOCR = pageTexts
    .map { $0.joined(separator: "\n") }
    .joined(separator: "\n===PAGE===\n")         // keeps page context
    .replacingOccurrences(of: " {2,}", with: " ", options: .regularExpression)
    .replacingOccurrences(of: "-\n",    with: "")   // joins hyphen-breaks

3.5  Call Gemini in “JSON mode”

let prompt = buildPrompt(with: rawOCR)          // insert schema + hard rules
let response = try await gemini.chatJSON(prompt) // JSON-only mode, temperature≈0
let statement = try Statement.parse_raw(response) // Pydantic equivalent in Swift: SwiftCodable + JSONSchema

3.6  Enforce UPI category & statement-period fallback

for i in statement.transactions.indices {
    let desc = statement.transactions[i].description.uppercased()
    if desc.contains("UPI") { statement.transactions[i].derived?.category = "UPI" }
}

// If LLM missed statement period, regex fallback
if statement.card?.statementPeriod == nil {
    if let match = rawOCR.firstMatch(of: #"(?i)Statement Period.*?(\d{1,2}\s\w{3}\s\d{2,4}).*?(\d{1,2}\s\w{3}\s\d{2,4})"#) {
        statement.card?.statementPeriod = .init(from: parse(match.1), to: parse(match.2))
    }
}

3.7  Persist & use
	•	Store Statement in Core Data or Realm.
	•	Feed transactions to your budgeting UI.
	•	Optionally re-prompt Gemini for categories only to save tokens.

⸻

4️⃣  Why this works (first-principles)

Principle	Implementation
Single source of truth	JSON schema validated immediately after LLM call. No silent drift.
Deterministic OCR	Vision uses on-device ML → no network, no privacy fuss. Supports multi-language and is rock-solid at 300 dpi  ￼
Token-efficient	Pre-clean + hard rules means the LLM never sees tables/ads and therefore costs < 5 ¢ per statement.
Explicit fallbacks	Regex for statement period & UPI post-process guarantee 100 % coverage even if the LLM stumbles.


⸻

Next tasks for your AI coder
	1.	Unit-test every regex and JSON sample.
	2.	Add a retry loop for JSON-parsing errors with temperature += 0.1.
	3.	Cache identical pages’ OCR with a SHA-256 hash so users aren’t re-charged for re-uploads.

Functional explanation of the feature:

Exactly—once you’ve done the heavy lifting in your app (PDF→images→OCR→cleaned text), Gemini’s sole responsibility is to turn that text into the exact JSON shape you defined.

In our architecture it breaks down like this:
	1.	On-device iOS (Swift) code
	•	Pick the PDF
	•	Rasterize every page at 300 dpi
	•	Run Vision OCR to get plain text
	•	Pre-clean (collapse spaces, merge hyphens, insert ===PAGE===)
	•	Handle any simple fallbacks (e.g. regex for statement period if LLM misses it)
	2.	AI (Gemini or another model)
	•	Input: your cleaned OCR blob + the JSON schema + “Hard rules” (credit markers, UPI override, omit-if-uncertain, etc.)
	•	Output: one chunk of valid JSON that:
	•	Lists every transaction (date, description, amount, currency, type)
	•	Captures statement period
	•	Optionally includes summary & derived fields
	3.	Back to your Swift code
	•	Decode/validate with Codable (or Pydantic if you were in Python)
	•	Post-process any final rules (e.g. force category = "UPI" on UPI lines)
	•	Persist to Core Data
	•	Render charts & lists

⸻

Why this separation works
	•	Deterministic pre-processing (OCR + clean) guarantees your AI prompt is always fed the same kind of text, page-after-page.
	•	Schema-first prompting makes your AI 100 % focused on “give me JSON,” so you never have to parse free-text.
	•	Swift handles UI, storage & fallback logic, so if Gemini hiccups you can retry or fall back safely.

So yes—all the “structuring” lives in your AI prompt + schema. Your app’s job is to get clean text in and to consume the clean JSON out.